#!/usr/bin/env python3

"""
@desc:  Tool to handle big endian binary files: split, write to ascii, print to stdout, etc.
@auth:  Jayghosh S. Rao
@usage: ./dumpy <FILES> {-w outfile | -p} {-s <number of splits>} {-v <d | i>} {-z} {-d}
@help: ./dumpy -h
@examples:
    $ dumpy mrng -v i -p -n 4 | vim
    $ dumpy two-spheres.ascii -v f -e '<' -w two-spheres.xyzd -a
    $ dumpy two-spheres.xyzd0 -v f -e '<' -p
    $ dumpy --packing packing.xyzd --nfo packing.nfo -w fixed.xyzd
    $ dumpy dummy --fill <value> <n_nodes> -n <ndf> -w dummy -v <vartype>
"""

# TODO: assert array element sizes before writing (int: 4 bytes, float: 4 bytes, double: 8 bytes)
# DONE: in unchunked files, don't append 0 to output filename
# DONE: Handle packing file and particle diameter scaling? Scale every nth value (scale-step?) by sf (scale-factor

# TODO: Create or Fill files with values (zeroes, custom values etc) for testing

# DONE: matplotlib for top view/side view of column?

from __future__ import print_function

import argparse
import struct
import sys
import itertools
import numpy as np
import matplotlib.pyplot as plt

def bin_to_arr(filename, f):
    with(open(filename, 'rb')) as input:
        myiter = struct.iter_unpack(f, input.read())

        arr = []
        for i in myiter:
            arr.append(i[0])

        return arr

        # arr2 = arr[len(arr)//2:]
        # arr2 = arr[0:len(arr)//2]

def arr_to_bin(arr, filename, f):
    with(open(filename, 'wb')) as output:
        for i in arr:
            output.write(struct.pack(f, i))

def arr_to_ascii(arr, filename):
    with(open(filename, 'w')) as output:
        for item in arr:
            output.write(item)

def ascii_to_arr(filename, vartype):
    with(open(filename, 'r')) as inputfile:
        arr = []
        for line in inputfile:
            val = line.strip()
            arr.append(val)
        if(vartype == 'i'):
            arr = [ int(x) for x in arr]
        elif(vartype == 'f'):
            arr = [ np.float32(x) for x in arr]
        elif(vartype == 'd'):
            arr = [ float(x) for x in arr]
        return arr


def print_data(arr, n, vartype):
    if vartype == 'd':
        for chunk in grouper(arr,n):
            print("\t".join("%.6E" % x for x in chunk))
    elif vartype == 'i':
        for chunk in grouper(arr,n):
            print("\t".join("%d" % x for x in chunk))
    elif vartype == 'f':
        for chunk in grouper(arr,n):
            print("\t".join("%.6E" % x for x in chunk))
    # for item in arr:
    #     print(item)



def grouper(iterable, n):
    it = iter(iterable)
    while True:
       chunk = tuple(itertools.islice(it, n))
       if not chunk:
           return
       yield chunk

def scatterPlot(x, y):
    fig, ax = plt.subplots()
    ax.scatter(x, y)
    ax.legend(loc='best', shadow=True)
    ax.set(title='Top View')
    ax.set(xlabel='X')
    ax.set(ylabel='Y')
    ax.autoscale(tight=True)
    fig.savefig('plot.pdf')
    fig.savefig('plot.jpg', dpi=300)
    # plt.show()

def calcFinalScalingFactor(filename):
    """
    Newly generated meshes with packinggenerator are out of scale, beads need to be unshrunk.
    """
    data = {}
    with open(filename) as fp:
        for line in fp:
            linesplit = line.strip().split(':')
            data.update({linesplit[0].strip() : linesplit[1].strip().split('(')[0].strip()})
    por_theoretical = float(data['Theoretical Porosity'])
    por_final = float(data['Final Porosity'])

    final_scaling_factor = ( (1-por_final) / (1-por_theoretical) )**(1/3)
    print("Final Scaling Factor:", final_scaling_factor, file=sys.stderr)
    return final_scaling_factor


def mixdInfo(filename, length):
    print("Assuming tetrahedrons.")
    nen = 4
    nef = 4
    nsd = 3
    ne = 0
    if 'mien' in filename:
        ne = length / nen
        print("ne: {ne}".format(ne=ne))
    elif 'mxyz' in filename:
        nn = length / nsd
        print("nn: {nn}".format(nn=nn))
    elif 'mrng' in filename:
        nrng = length / nef ## TODO: check if this is right
        print("nrng: {nrng}".format(nrng=nrng))


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--plot", action='store_true', help="Plot X Y as scatter plot")
    ap.add_argument("-p", "--print", action='store_true', help="Print to STDOUT")
    ap.add_argument("-a", "--ascii_input", action='store_true', help="input is ascii file")
    ap.add_argument("-v", "--vartype", help="type of variable stored (d | i)", default='d', choices=['d', 'f', 'i'])
    ap.add_argument("-e", "--endianness", help="> or <", default='>')
    ap.add_argument("-n", "--ndf", help="number of items per row", default=1, type=int)
    ap.add_argument("-s", "--split", help="split file into pieces", default = 1, type=int)
    ap.add_argument("-w", "--write", help="write to bin file")
    ap.add_argument("-so", "--scale-offset", help="Scale every ndf'th number starting from scale-offset. Index starts from 0.", default=0, type=int)
    ap.add_argument("-sf", "--scale-factor", help="Scale every ndf'th number starting from scale-offset.", default=1, type=float)
    ap.add_argument("-z", "--zero-pad", action='store_true', help="Pre-pad file with zeroes")
    ap.add_argument("-d", "--double", action='store_true', help="Double the file. Useful for converting semi-discrete to space-time data, although cat is better.")
    ap.add_argument("-f", "--fill", nargs=2, default = [0, 0], help="Fill the given file with values")
    ap.add_argument("--dpacking", action='store_true', help="Input file is packing.xyzd with e=< and n=4 v=d.")
    ap.add_argument("--fpacking", action='store_true', help="Input file is packing.xyzd with e=< and n=4 v=f.")
    ap.add_argument("--nfo", help="Read newly generated packing data and calculate final scaling factor from NFO file.")
    ap.add_argument("--norm", help="Norm order")
    ap.add_argument("--norm-var", help="Calculate Norm for this variable. Index starts at 0.")
    ap.add_argument("-i", "--info", action='store_true', help="Dump info.")
    ap.add_argument("FILES", nargs='*', help="files")
    args = vars(ap.parse_args())

    if args['dpacking']:
        args['ndf'] = 4
        args['endianness'] = '<'
        args['plot'] = True
        args['vartype'] = 'd'

    if args['fpacking']:
        args['ndf'] = 4
        args['endianness'] = '<'
        args['plot'] = True
        args['vartype'] = 'f'

    if args['nfo']:
        final_scaling_factor = calcFinalScalingFactor(args['nfo'])
        args['scale_offset'] = 3
        args['scale_factor'] = final_scaling_factor

    vartype = args['vartype']
    ndf = args['ndf']
    endianness = args['endianness']
    dataformat = endianness + vartype

    scale_offset= args['scale_offset']
    scale_factor = args['scale_factor']

    infiles = args['FILES']

    # if args['fill']:
    #     args['write'] = args['FILES']

    # split = 1
    # if args['split']:
    #     split = args['split']

    print('Note: Default endianness is big (>) to deal with xns files.', file=sys.stderr)

    for infile in infiles:
        # Input
        print("Infile: ", infile, file=sys.stderr)

        if args['ascii_input']:
            array = ascii_to_arr(infile, vartype)
        else:
            array = bin_to_arr(infile, dataformat)

        ## Apply scale_factor to every ndf'th number
        ## Best for scaling the last variable (step = n), or the entire column (step = 1)
        array[scale_offset::args['ndf']] = [x*scale_factor for x in array[scale_offset::args['ndf']]]

        normDict = {
                '0':0,
                'avg': 0,
                '1':1,
                '2':2,
                'max': np.inf,
                'fro': 'fro'
                }

        if args['norm_var']:
            norm = np.linalg.norm(array[ int(args['norm_var']):: int(args['ndf']) ], ord=normDict[args['norm']])
            print(args['norm'], "norm of var at pos", args['norm_var'], "is", norm)
            if args['norm'] == 'avg':
                asum = sum(array[int(args['norm_var']) :: int(args['ndf']) ])
                alen = len(array[int(args['norm_var']) :: int(args['ndf']) ])
                print("Average of var[%s] over %d values is %f" % (args['norm_var'], alen, asum/alen ) )

        # Modifications
        zero_array = [ 0 for item in array ]
        if args['zero_pad']:
            array = zero_array + array

        if args['double']:
            array = array + array

        if args['fill']:
            if(vartype == 'i'):
                dummy = [ int(args['fill'][0]) ]
            elif(vartype == 'f'):
                dummy = [ float(args['fill'][0]) ]
            elif(vartype == 'd'):
                dummy = [ float(args['fill'][0]) ]
            array.extend( dummy * args['ndf']*int(args['fill'][1]))

        # to split the file into chunks
        out_arrays = []
        out_arrays = np.array_split(np.array(array), args['split'])

        # Output to STDOUT
        if args['print']:
            for arr in out_arrays:
                print_data(arr, ndf, vartype)

        if args['info']:
            for arr in out_arrays:
                print('Type:', type(arr[0]))
                print('Serial Length:', len(arr))
                print('Proper Length:', len(arr) / ndf)
                mixdInfo(args['FILES'][0], len(arr))


        # Write to BIN output file
        if args['write']:
            if len(out_arrays) > 1:
                for count, arr in enumerate(out_arrays):
                    writeoutfile = args['write'] + str(count)
                    arr_to_bin(arr, writeoutfile, dataformat)
            else:
                # arr_to_bin(arr, args['write'], dataformat)
                arr_to_bin(out_arrays[0], args['write'], dataformat)

        # To quickly plot a packing to see if it's square/cylindrical, and ordered/random
        if args['plot']:
            for arr in out_arrays:
                x = [ arr[i] for i in range(len(arr)) if i%4 == 0 ]
                y = [ arr[i] for i in range(len(arr)) if i%4 == 1 ]
                scatterPlot(x,y)

if __name__ == "__main__":
    # print(__doc__)
    main()
