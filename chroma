#!/usr/bin/env python3

"""
@desc:  Tool to prepare 3D chromatography meshes for XNS use.
        Can handle parallel preparation (parallel FLOW and MASS prep) for small meshes locally. (Large meshes backend untested)
        Requires gmsh2mixd, shiftmixd, scalemixd, rmmat, gennmat, decompose.metis, and sub.sh
@auth:  Jayghosh S. Rao
@usage: chroma *.msh2 {optional: -e <execstring>}
@usage: chroma --restart previous
"""

# TODO: phase out sub.sh?
# TODO: On JURECA: devel salloc has limit of 2 hours. If mesh is larger, multiple meshes can't be done together.
# TODO: (backend) decompose load required modules
# TODO: backend decompose is not perfect with multi: srun produced error. temp fixed
# TODO: meta-wrapper where I can specify a table of data that runs multiple simulations
# TODO: vipe the config if it doesn't exist
# TODO: handle second order and first order meshes: Allow specifying the full gendual/genneim and other commands in the config file.
# TODO: kernel optional argument mshfile
# TODO: kernel async pool decompose mass fix
# TODO: Stop using job.sh template file. Build it.

import re
import sys
import json
import shutil
import argparse
import subprocess

from pathlib import Path
from os import environ, chdir, stat
from tempfile import NamedTemporaryFile
from multiprocessing import Pool, current_process

if 'jureca' in str(environ.get('HOSTNAME')):
    from env_modules_python import module # type: ignore

def find_up_recursive(name, startdir='.', stopdir='~'):
    path = Path(startdir).resolve()                   ## start searching in startdir
    stop = Path(stopdir).resolve().parent.resolve()   ## search in the stopdir, but not beyond. stopdir is inclusive
    print('Searching recursively until', Path(stopdir).resolve() )
    while path != stop:
        res = [ x for x in path.rglob(name)]
        if res:
            return res[0]
        path = path.parent

execstring=None
CONFIGFILE = 'chroma.json'
STAGE = 'Stages/2018a'
TEMPLATEDIR = Path('~/templates').expanduser()
config = {}
LOG_FILE = 'chrom.out'
ROOT = Path.cwd()
LOG = ROOT.joinpath(LOG_FILE)

NEN = "4 "
ETYPE = "tet "

def sed_inplace(filename, pattern, repl):
    '''
    Perform the pure-Python equivalent of in-place `sed` substitution: e.g.,
    `sed -i -e 's/'${pattern}'/'${repl}' "${filename}"`.
    '''
    # For efficiency, precompile the passed regular expression.
    pattern_compiled = re.compile(pattern)

    # For portability, NamedTemporaryFile() defaults to mode "w+b" (i.e., binary
    # writing with updating). This is usually a good thing. In this case,
    # however, binary writing imposes non-trivial encoding constraints trivially
    # resolved by switching to text writing. Let's do that.
    with NamedTemporaryFile(mode='w', delete=False) as tmp_file:
        with open(filename) as src_file:
            for line in src_file:
                tmp_file.write(pattern_compiled.sub(repl, line))

    # Overwrite the original file with the munged temporary file in a
    # manner preserving file attributes (e.g., permissions).
    shutil.copystat(filename, tmp_file.name)
    shutil.move(tmp_file.name, filename)

def run_command_in_shell(cmdstring):
    reprint(cmdstring)
    p = subprocess.Popen(cmdstring, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=True)
    stdout, stderr = p.communicate()
    # LOG = Path.cwd().joinpath(LOG_FILE)
    with open(LOG, 'a') as logfile:
        logfile.write(stdout)
        logfile.write(stderr)
    if stderr.strip() != "":
        print('---')
        print(stderr)
        print('---')
    else:
        return stdout

def run_command(cmdstring):
    reprint(cmdstring)
    p = subprocess.Popen(cmdstring.split(' '), stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
    stdout, stderr = p.communicate()
    # LOG = Path.cwd().joinpath(LOG_FILE)
    with open(LOG, 'a') as logfile:
        logfile.write(stdout)
        logfile.write(stderr)
    if stderr.strip() != "":
        print('---')
        print(stderr)
        print('---')
    else:
        return stdout


def check_prerequisites(programs=None):
    print("Checking Prerequisites...")
    if programs is None:
        programs = ['gmsh2mixdv2', 'shiftmixd', 'scalemixd', 'rmmat', 'gennmat', 'decompose.metis', 'genmprd', 'dumpy']
    prgExists = [(shutil.which(prg) is not None) for prg in programs]
    if False in prgExists:
        print("\n".join("{}: {}".format(x,y) for x, y in zip(programs, prgExists)))
        sys.exit(-1)

    if not TEMPLATEDIR.is_dir():
        print("No templates found!")
        sys.exit(-1)


def read_config():
    with open(CONFIGFILE) as json_file:
        config.update( json.load(json_file))
    if (config['job-name'] == 'DIR'):
        rootDir = Path.cwd().stem
        config['job-name'] = rootDir
    if (config['mesh-order']) == "2":
        global NEN, ETYPE
        NEN = "10 "
        ETYPE = "tetP2 "

    if args['decompose']:
        config['decompose'] = args['decompose']
    if args['nparts']:
        config['job-cpus'] = args['nparts'] ## TODO: consider renaming job-cpus and other job- tags?
    if args['periodic']:
        config['periodic'] = args['periodic']



def setup_dirs():
    reprint("Creating FLOW directory...")
    Path("FLOW/mesh").mkdir(parents=True, exist_ok=True)
    # shutil.copy(TEMPLATEDIR.joinpath('xns.flow.in'      ), 'FLOW'     )
    # shutil.copy(TEMPLATEDIR.joinpath('job.flow.sh'      ), 'FLOW'     )

    reprint("Creating MASS directory...")
    Path("MASS/mesh").mkdir(parents=True, exist_ok=True)
    # shutil.copy(TEMPLATEDIR.joinpath('xns.mass.in'      ), 'MASS'     )
    # shutil.copy(TEMPLATEDIR.joinpath('job.mass.sh'      ), 'MASS'     )

def edit_files(FILES:list):
    EDITOR = environ.get('EDITOR','vim')
    cmdlist = [EDITOR]
    cmdlist.extend(FILES)
    subprocess.call(cmdlist)

def set_stage():
    # if environ.get('LMOD_DIR'):
    if 'jureca' in str(environ.get('HOSTNAME')):
        # module('--force purge')
        # module('use /usr/local/software/jureca/OtherStages')
        # module('load ' + STAGE)
        module('load intel-para Boost flex')


def transform_mixd():
    run_command('shiftmixd ' + ETYPE +  config['shift'])
    run_command('scalemixd ' + ETYPE +  config['scale'])

def gen_spacetime_mesh(mshfile):
    run_command('gmsh2mixdv2 -d 4 -o ' + config['mesh-order'] + ' ' + mshfile)
    # run_command('gmsh2mixd_3D -d 4 -m sd ' + mshfile)
    if config['transform'] == 'yes':
        transform_mixd()

    ## Some code in XNS: genmesh.F / genmtbl()/genmprd() etc allows us
    ## to just duplicate the semidiscrete data to generate the spacetime data.
    ## So we just generate mtbl and mprd for semidiscrete meshes and then double it.
    ## To be "proper", we'd have to add an offset (nnspace) to the second half of the mtbl/mprd data
    if 'xy' in config['periodic']:
        run_command('genmprd 0 0 x -readmtbl')
        run_command('genmprd 0 0 y -readmprd -readmtbl')
    if 'z' in config['periodic']:
        run_command('genmprd 0 0 z -readmprd -readmtbl')

    shutil.copy('mxyz', 'mxyz.space')
    shutil.copy('mtbl', 'mtbl.space')
    run_command_in_shell('cat mxyz.space >> mxyz')
    run_command_in_shell('cat mtbl.space >> mtbl')

    if config['periodic'] != "no":
        shutil.copy('mprd', 'mprd.space')
        run_command_in_shell('cat mprd.space >> mprd')

    shutil.copy("minf", "minf.space")
    nn = int( run_command('tail -n 1 minf').split()[1] )
    nn_st = nn * 2
    sed_inplace('minf', 'nn', '# nn')
    run_command_in_shell('echo "nn     '+str(nn_st)+'" >> minf')
    for mfile in ['mien', 'mxyz', 'mrng', 'minf', 'mtbl', 'mmat', 'mprd', 'mtbl.space', 'mxyz.space', 'mtbl.dual', 'minf.space', 'mprd.space']:
        try:
            shutil.move(mfile, 'MASS/mesh/' + mfile)
        except:
            print("Couldn't move", mfile, "!")
    remove_beads()

def remove_beads():
    root = Path.cwd()
    chdir('MASS/mesh/')
    run_command('rmmat -'+ ETYPE + '-st ../../FLOW/mesh 2')
    chdir(root)

    chdir('FLOW/mesh/')
    if 'xy' in config['periodic']:
        run_command('genmprd 0 0 x')
        run_command('genmprd 0 0 y -readmprd')
    if 'z' in config['periodic']:
        run_command('genmprd 0 0 z -readmprd')
    chdir(root)


    with Pool(processes=2) as pool:
        pool.apply_async(partition_flow)
        pool.apply_async(partition_mass)
        pool.close()
        pool.join()

def partition_flow():
    root = Path.cwd()
    chdir('FLOW/mesh/')

    if config['partition'] == 'yes':
        run_command('gendual -e ' + ETYPE)
        run_command('genneim --nen ' + NEN)
    else:
        reprint("Not partitioning mesh")

    chdir(root)
    decompose_flow()

def decompose_flow():
    root = Path.cwd()
    chdir('FLOW/mesh/')

    if config['decompose'] != 'no':
        # if environ.get('LMOD_DIR'):
        if 'jureca' in str(environ.get('HOSTNAME')):
            module('load GCC/9.3.0 ParaStationMPI/5.4.7-1 ParMETIS/4.0.3-double Boost')

    if config['decompose'] == 'no':
        reprint("Not decomposing mesh")
    elif config['decompose'] == 'yes':
        run_command('decompose.metis -e ' + ETYPE + '-w -p ' + config['job-cpus'])
    elif config['decompose'] == 'mpi':
        run_command('mpiexec -np ' + config['decompose-nprocs'] + ' decompose.metis -e '+ ETYPE + '-w -p ' + config['job-cpus'])
    elif config['decompose'] == 'backend':
        run_command('srun -N ' + config['decompose-nnodes'] + ' -n' + config['decompose-nprocs'] + ' -A ' + config['job-acct'] + ' -p ' + config['decompose-backend'] + ' decompose.metis -e ' + ETYPE + '-w -p ' + config['job-cpus'])

    chdir(root)
    setup_flow()

def partition_mass():
    root = Path.cwd()
    chdir('MASS/mesh/')

    if config['partition'] == 'yes':
        run_command('gendual -e ' + ETYPE)
        run_command('genneim --nen ' + NEN + '-s')
    else:
        reprint("Not partitioning mesh")

    chdir(root)
    decompose_mass()

def decompose_mass():
    root = Path.cwd()
    chdir('MASS/mesh/')

    if config['decompose'] != 'no':
        # if environ.get('LMOD_DIR'):
        if 'jureca' in str(environ.get('HOSTNAME')):
            module('load GCC/9.3.0 ParaStationMPI/5.4.7-1 ParMETIS/4.0.3-double Boost')

    if config['decompose'] == 'no':
        reprint("Not decomposing MASS mesh")
    elif config['decompose'] == 'yes':
        run_command('decompose.metis -e '+ ETYPE + '--mprd mtbl -w -p ' + config['job-cpus'] + ' -s')
    elif config['decompose'] == 'mpi':
        run_command('mpiexec -np ' + config['decompose-nprocs'] + ' decompose.metis -e ' + ETYPE + '--mprd mtbl -w -p ' + config['job-cpus'] + ' -s')
    elif config['decompose'] == 'backend':
        run_command('srun -N ' + config['decompose-nnodes'] + ' -n' + config['decompose-nprocs'] + ' -A ' + config['job-acct'] + ' -p ' + config['decompose-backend'] + ' decompose.metis -e ' + ETYPE + '--mprd mtbl -w -p ' + config['job-cpus'] + ' -s')

    ## TODO: check that this is proper
    run_command('gennmat ' + NEN + 'st')
    chdir(root)
    setup_mass()

def setup_flow():
    root = Path.cwd()
    Path("FLOW/sim").mkdir(parents=True, exist_ok=True)
    # shutil.copy('FLOW/xns.flow.in', 'FLOW/sim/xns.in')
    if(Path('xns.flow.in').exists()):
        shutil.copy('xns.flow.in', 'FLOW/sim/xns.in')
    if(Path('FLOW/job.flow.sh').exists()):
        shutil.copy('FLOW/job.flow.sh', 'FLOW/sim/job.sh')
        chdir('FLOW/sim')
        sed_inplace('job.sh', r'<job_name>', config['job-name'])
        sed_inplace('job.sh', r'<job_cpus>', config['job-cpus'])
        sed_inplace('job.sh', r'<job_acct>', config['job-acct'])
        sed_inplace('job.sh', r'<job_part>', config['job-part'])
        sed_inplace('job.sh', r'<job_flow_time>', config['job-flowtime'])
        sed_inplace('job.sh', r'<xns_path>', config['xns-path'])
        chdir(root)
    setup_mass()

def setup_mass():
    root = Path.cwd()
    Path("MASS/sim").mkdir(parents=True, exist_ok=True)
    # shutil.copy('MASS/xns.mass.in', 'MASS/sim/xns.in')
    if(Path('xns.mass.in').exists()):
        shutil.copy('xns.mass.in', 'MASS/sim/xns.in')
    if(Path('MASS/job.mass.sh').exists()):
        shutil.copy('MASS/job.mass.sh', 'MASS/sim/job.sh')
        chdir('MASS/sim')
        sed_inplace('job.sh', r'<job_name>', config['job-name'])
        sed_inplace('job.sh', r'<job_cpus>', config['job-cpus'])
        sed_inplace('job.sh', r'<job_acct>', config['job-acct'])
        sed_inplace('job.sh', r'<job_part>', config['job-part'])
        sed_inplace('job.sh', r'<job_mass_time>', config['job-masstime'])
        sed_inplace('job.sh', r'<xns_path>', config['xns-path'])
    chdir(root)
    # submit_sims()

##
## !!!! Untested & mostly unused
##
def submit_sims():
    root = Path.cwd()
    if config['submit'] == 'yes':
        # prompt = input("Did you check your inputs? Are you sure you want to submit simulations? (y/n): ")
        # if(prompt == 'y'):
        chdir('FLOW/sim')
        FJOUT = run_command('sub.sh -r')
        FJID = FJOUT.split()[-1]
        chdir(root)
        chdir('MASS/sim')
        sed_inplace('job.sh', r'<flow_jobid>', FJID)
        sed_inplace('job.sh', r'##SBATCH -d', '#SBATCH -d')
        run_command('sub.sh -r')
        chdir(root)
    else:
        chdir('MASS/sim')
        sed_inplace('job.sh', r'#SBATCH -d', '##SBATCH -d')
        chdir(root)


def create_config():
    config["mesh-order"] = "1"
    config["mesh-dim"] = "3"
    config["transform"] = "no"
    config["shift"] = ""
    config["scale"] = ""
    config["periodic"] = "no"
    config["job-name"] = "DIR"
    config["job-cpus"] = "0"
    config["job-acct"] = "jibg12"
    config["job-part"] = "batch"
    config["job-flowtime"] = "02:00:00"
    config["job-masstime"] = "24:00:00"
    config["xns-path"] = "~/bin/xns-mpi"
    config["partition"] = "yes"
    config["decompose"] = "no"
    config["decompose-backend"] = "dc-cpu-devel"
    config["decompose-np"] = "128"
    config["decompose-N"] = "2"
    config["submit"] = "no"

    with open(CONFIGFILE, 'w') as json_file:
        json.dump(config, json_file, indent=4)


def kernel(mshfile):
    """
    This function should be renamed to driver or controller or something.
    """
    root = Path.cwd()
    # base, mshfile = os.path.split(os.path.abspath(mshfile))
    mshfile = Path(mshfile).absolute().name
    base = Path(mshfile).absolute().parent
    chdir(base)
    read_config()

    execstring = args['execute']

    if (execstring is None):
        setup_dirs()
        # edit_files()
        gen_spacetime_mesh(mshfile)
    elif (execstring == 'rmmat'):
        remove_beads()
    elif (execstring == 'part'):
        with Pool(processes=2) as pool:
            pool.apply_async(partition_flow)
            pool.apply_async(partition_mass)
            pool.close()
            pool.join()
    elif (execstring == 'pf'):
        partition_flow()
    elif (execstring == 'pm'):
        partition_mass()
    elif (execstring == 'dec'):
        with Pool(processes=2) as pool:
            pool.apply_async(decompose_flow)
            pool.apply_async(decompose_mass)
            pool.close()
            pool.join()
    elif (execstring == 'df'):
        decompose_flow()
    elif (execstring == 'dm'):
        decompose_mass()
    elif (execstring == 'set'):
        setup_flow()
    elif (execstring == 'sub'):
        config['submit'] = 'yes'
        submit_sims()
    elif (execstring == 'edit'):
        edit_files()
    else:
        reprint("Bad Execstring!")

    chdir(root)

def restart(directory):
    """
    Ideally i'd like this script to handle the work that goes into restarting of xns sims,
    but on a cluster, shell scripts are the best since they don't need any dependent modules.
    so I'll continue to use postsim.sh on JURECA even though it pains me.

    @deps: exts (extract data.out->data.in from data.all) (perhaps use dumpy for this?)
    @deps: sed_inplace
    """
    # findup mesh dir -> minf -> nn
    print("restarting xns chromatography simulation...")
    minffile = find_up_recursive('minf', stopdir='..')

    if minffile:
        print("Found minf!")
    else:
        raise(FileNotFoundError)

    nn = 0
    with open(minffile.resolve(), 'r') as minf:
        for line in minf:
            if line.strip()[0] != '#':
                if 'nn' in line:
                    nn = int(line.split()[1])
    print("nn:", nn)

    # Get nrec from data.all
    data_all_size = Path('data.all').stat().st_size
    nrec = data_all_size / (nn * 2 * 8)             ## ndf = 2, sizeof(double) = 8
    lastrec = nrec-1

    print("nrec:", nrec)
    print("extracting last record with index:", lastrec)

    # dumpy data.all --extract-slice data.in --nrows nn --ndf 2 --skip <>
    run_command_in_shell("dumpy data.all --extract-slice data.in --nrows {nn} --ndf 2 --skip {lastrec}".format(nn=nn, lastrec=int(lastrec)))

    print("moving files...")

    # move/copy files to new directory
    Path(directory).mkdir()
    shutil.move(Path('chromatogram'), Path(directory))
    shutil.move(Path('data.all'), Path(directory))
    shutil.move(Path('xns.log'), Path(directory))
    shutil.copy(Path('xns.in'), Path(directory))
    shutil.copy(Path('.xns.time'), Path(directory))
    for item in Path('.').glob('out-*'):
        shutil.move(item, Path(directory))
    for item in Path('.').glob('*.err'):
        shutil.move(item, Path(directory))

    # get new starttime
    starttime = 0
    with open('.xns.time', 'r') as timefile:
        starttime = float(timefile.read())

    print("starttime:", starttime)

    print("modifying xns.in with 'restart on' and 'starttime {starttime}'".format(starttime=starttime))
    # edit xns.in/job.sh as required
    sed_inplace('xns.in', r'restart\s+off', 'restart on')
    sed_inplace('xns.in', r'starttime\s.*', 'starttime {starttime}'.format(starttime=starttime))

def reprint(string):
    thread = current_process().name
    print(thread, ": " , string)

def stitch(first:str, second:str):
    check_prerequisites(['stitchperiodic'])
    print("Ensure that run directory contains inlet/outlet/column subdirs fully formed.")
    root = Path.cwd()
    chdir(first + '/FLOW/sim')
    run_command('stitchperiodic data.out --ndf 4 --rng 2 --nts 2')
    shutil.copy('rng.data', '../../../' + second + '/FLOW/sim/rng.data.in')
    shutil.copy('rng.xyz', '../../../' + second + '/FLOW/sim/rng.xyz.in')
    flowstat = stat('rng.xyz')
    print("Done with flow. nn_rng:", flowstat.st_size/(3*8))

    chdir('../../MASS/sim')
    nn = stat('../mesh/mxyz').st_size/(3*8)
    nts = stat('data.all').st_size/(2*nn*8) # ndf = 2, timesteps to stitch are calculated
    run_command('stitchperiodic data.all --ndf 2 --rng 2 --nts ' + str(nts) + ' -s')
    shutil.copy('rng.data', '../../../' + second + '/MASS/sim/rng.data.in')
    shutil.copy('rng.xyz', '../../../' + second + '/MASS/sim/rng.xyz.in')
    massstat = stat('rng.xyz')
    print("Done with mass. nn_rng:", massstat.st_size/(3*8))
    print("Ensure that xns.in files are properly written.")
    chdir(root)
    # edit_files([second + '/FLOW/sim/xns.in', second + '/MASS/sim/xns.in'])


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("-c", "--create-config", action='store_true', help="create an example config.json")
    ap.add_argument("-e", "--execute", help="execstring", choices=['rmmat', 'part', 'pf', 'pm', 'dec', 'df', 'dm', 'set', 'sub', 'edit'])
    ap.add_argument("-r", "--restart", help="restart chromatography simulation in current simulation directory. Provide name of new folder to store old data")
    ap.add_argument("--stitch", nargs=2, help="stitch periodic sections of a column together")
    ap.add_argument("FILES", nargs='*', help="files")

    ##TODO: Commandline args for config overrrides
    ap.add_argument("-np", "--nparts", help="Number of decompose parts and job processes.")
    ap.add_argument("--decompose", type=str, choices=["no", "yes", "mpi", "backend"], help="Override config and force decompose.")
    ap.add_argument("--periodic", type=str, choices=["no", "xy", "xyz"], help="Override config and force periodic.")


    ## TODO: unglobal this
    global args
    args = vars(ap.parse_args())

    if args['create_config']:
        create_config()
        print("Config file created")
        # sys.exit(0)

    # check_prerequisites()
    set_stage()

    if args['restart']:
        restart(args['restart'])
    elif args['stitch']:
        stitch(args['stitch'][0], args['stitch'][1])
    else:
        ## serial execution
        for mshfile in args['FILES']:
            kernel(mshfile)

    print("Done!")

if __name__ == "__main__":
    main()
